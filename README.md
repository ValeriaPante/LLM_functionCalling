# LLM Function Calling

LLM function calling is a feature that allows large language models (LLMs) to interact with external tools and APIs. This basically means that LLMs can now understand and use functions from other programs to complete tasks or improve their responses.

Here's how it works:
1. User Input: You provide a prompt or question to the LLM, along with information about available tools and their functionalities.
2. LLM Understanding: The LLM analyzes your prompt and the available functions to see if any of them can be helpful. It might also ask you for additional information to fill in any gaps.
3. Function Call (if applicable): If the LLM finds a relevant function, it can call that function and use the results to answer your question or complete your request.
4. Final Response: The LLM combines the results from the function call (if any) with its own knowledge and understanding to provide you with the best possible answer.

This function calling capability makes LLMs more powerful for different reasons:
- Access to External Data: LLMs can now tap into information and functionalities from other programs, allowing them to provide more comprehensive and informative responses.
- Complex Tasks: By calling external functions, LLMs can perform actions that they wouldn't be able to do on their own, opening them up to a wider range of tasks.
- Improved Accuracy: By using data and tools from external sources, LLMs can potentially improve the accuracy and relevance of their responses.

More info on OpenAI function calling [here](https://platform.openai.com/docs/guides/function-calling).
